## DrugOOD: OOD Dataset Curator and Benchmark for AI-aided Drug Discovery


### Project Description

AI-aided drug discovery (AIDD) is gaining increasing popularity due to its promise of  making  the  search  for  new   pharmaceuticals  quicker,  cheaper  and  more  efficient.  Inspite of its extensive use in many fields,  such as ADMET prediction,  virtual screening, protein folding and generative chemistry, little has been explored in terms of the out-of-distribution (OOD) learning problem with _noise_, which is inevitable in real world AIDD applications.

In this work, we present DrugOOD, a systematic OOD dataset curator and benchmark for AI-aided drug discovery,  which comes with an open-source Python package that fully automates the data curation and OOD benchmarking processes.  We focus on one of the most crucial problems in AIDD: drug target binding affinity prediction, which involves both macromolecule (protein target) and small-molecule (drug compound).  In contrast to only providing fixed datasets, DrugOOD offers automated dataset curator with user-friendly customization scripts, rich domain annotations aligned with biochemistry knowledge,  realistic  noise  annotations  and  rigorous  benchmarking  of  state-of-the-art OOD algorithms.  Since the molecular data is often modeled as irregular graphs using graph neural network (GNN) backbones, DrugOOD also serves as a valuable testbed for _graph OOD learning_ problems.  Extensive empirical studies have shown a significant performance gap between in-distribution and out-of-distribution experiments, which highlights the need to develop better schemes that can allow for OOD generalization under noise for AIDD.


`Keywords`: AI-aided drug discovery (AIDD), graph OOD learning, OOD generalization, learning under noise, binding affinity prediction, drug-target interaction, virtual screening


### Dataset Curator

![overview_dataset](figures/overview_dataset.png)

DrugOOD provides large-scale, realistic, and diverse datasets for Drug AI OOD research. Specifically, DrugOOD focuses on the problem of domain generalization, in which we train and test the model on disjoint domains, e.g., molecules in a new assay environment.
Top Left: Based on the ChEMBL database, we present an automated dataset curator for customizing OOD datasets flexibly.
Top Right: DrugOOD releases realized exemplar datasets spanning different domain shifts. In each dataset, each data sample (x, y, d) is associated with a domain annotation d. We use the background colours <span style="color:lightblue;">lightblue</span> and   <span style="color:lightgreen;">green</span>  to denote the seen data and unseen test data.
Bottom: Examples with different noise levels from the DrugOOD dataset. DrugOOD identifies and annotates three noise levels (left to right: core, refined, general) according to several criteria, and as the level increases,  data volume increases and  more noisy sources are involved.

We construct all the datasets based on ChEMBL, which is a large-scale, open-access drug discovery database that aims to capture medicinal chemistry dataand knowledge across the pharmaceutical research and development process. We use thelatest release in the SQLite format:  ChEMBL 29.  Moreover,  we consider the setting of OOD and different noise levels, which is an inevitable problem when the machine learning  model  is  applied  to  the  drug  development  process.For  example,  when  predicting SBAP bioactivity in practice, the target protein used in the model inference could be very different from that in the training set and even does not belong to the same protein family. The real-world domain gap will invoke challenges to the accuracy of the model.  On the other  hand,  the  data  used  in  the  wild  often  have  various  kinds  of  noise,  e.g.   activities measured through experiments often have different confidence levels and different “cut-off” noise.  Therefore, it is necessary to construct data sets with varying levels of noise inorder to better align with the real scenarios.
![curator](figures/curator.png)
Overview of the automated dataset curator is shown above. We mainly implement three major steps based on the ChEMBL data source: noise filtering, uncertainty processing, and domain splitting. We have built-in 96 configuration files to generate the realized  datasets with the configuration of two tasks, three noise levels, four measurement types, and five domains.

### Benchmark

![benchmark](figures/benchmark.png)
DrugOOD conducts a comprehensive benchmark for developing and evaluating OOD generalization algorithms for AIDD. After loading any of the datasets generated by the data curator, users can flexibly combine different types of modules, including algorithms, backbones, etc., to develop OOD generalization algorithms in a flexible and disciplined manner.


### Experiments
Baseline results on  dataset drugood-sbap-core-ic50-protein for the six OOD algorithm is shown below.
In-distribution (ID) results correspond to the train-to-train setting. Parentheses show standard deviation across 3 replicates.

 | Algos | Val(ID)-ACC | Val(ID)-ACU | Val(OOD)-ACC |Val(OOD)-AUC | Test(ID)-ACC |Test(ID)-AUC| Test(OOD)-ACC | Test(OOD)-AUC|
 | ------ | ------     | --------- |    ----------- | ------------| -------------|------------|---------------|---------------|
|ERM| 88.92 | 89.62 | 85.74 | 72.26  | 89.23 | 90.32 | 83.04 | 68.62 |
|IRM|88.77 | 90.63 | 85.87 | 73.28  | 89.07  | 91.29 | 82.58  |67.66 |
|DeepCoral|89.03 |89.62 |85.88 |71.71 |89.16 |90.33 |82.87 |67.26 |
|DANN|88.33 |77.53 |85.65 |63.61 |88.53 |78.12 |83.96 |62.58|
|Mixup|89.14 | 90.41 |85.99 |71.06 |89.36 |91.11 |83.09 |68.25 |
|GroupDro|88.73 |88.51 |85.37 |72.95 |89.06 |89.36 |82.26 |67.62 |

### Code and Document

To be released.

### Paper

Preprint: <https://arxiv.org/abs/2201.09637>

### Contact

Email: <DrugAIOOD@gmail.com>
